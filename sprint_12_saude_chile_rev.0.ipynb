{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d39301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d04a9672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as st\n",
    "import math as mth\n",
    "import seaborn as sns\n",
    "from plotly import graph_objects as go\n",
    "import plotly.express as px\n",
    "import sys\n",
    "import getopt\n",
    "import re\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import OperationalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4ff26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Analisar argumentos da linha de comando para \n",
    "retornar o caminho do arquivo.\n",
    "\n",
    "Retorna:\n",
    "file_path (str): o caminho para o arquivo \n",
    "fornecido pelo usuário.\n",
    "'''\n",
    "\n",
    "def parse_arguments():\n",
    "    unixOptions = 'f:' # argumento no formato unix e ira retornar '-f'\n",
    "    gnuOptions = ['file='] # argumento no formato gnu e ira retornar '--file='\n",
    "\n",
    "    fullCmdArguments = sys.argv\n",
    "    argumentList = fullCmdArguments[1:] # excluir o nome do script\n",
    "\n",
    "    try:\n",
    "        arguments, valeus = getopt.getopt(argumentList, unixOptions, gnuOptions)\n",
    "    except getopt.error as err:\n",
    "        print(str(err))\n",
    "        sys.exit(2)\n",
    "    \n",
    "    file_path = ''\n",
    "\n",
    "    for currentArgument, currentValue in arguments:\n",
    "        if currentArgument in ('-f', '--file'):\n",
    "            file_path = currentValue\n",
    "            \n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0405f36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\carlo\\\\anaconda3\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py', '--f=c:\\\\Users\\\\carlo\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v3ee2594d20f59401162676b323c90e71c2979f7df.json']\n",
      "\n",
      "['--f=c:\\\\Users\\\\carlo\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v3ee2594d20f59401162676b323c90e71c2979f7df.json']\n"
     ]
    }
   ],
   "source": [
    "unixOptions = 'f:'\n",
    "gnuOptions = ['file=']\n",
    "\n",
    "fullCmdArguments = sys.argv\n",
    "argumentList = fullCmdArguments[1:] # excluir o nome do script\n",
    "\n",
    "print(fullCmdArguments)\n",
    "print()\n",
    "print(argumentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8bdf34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('--file', 'c:\\\\Users\\\\carlo\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v3ee2594d20f59401162676b323c90e71c2979f7df.json')] []\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    arguments, valeus = getopt.getopt(argumentList, unixOptions, gnuOptions)\n",
    "    print(arguments, valeus)\n",
    "except getopt.error as err:\n",
    "    print(str(err))\n",
    "    sys.exit(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a97bf391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3ee2594d20f59401162676b323c90e71c2979f7df.json\n"
     ]
    }
   ],
   "source": [
    "file_path = ''\n",
    "\n",
    "for currentArgument, currentValue in arguments:\n",
    "    if currentArgument in ('-f', '--file'):\n",
    "        file_path = currentValue\n",
    "        \n",
    "print(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bfbec6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extrair o ano do nome do caminho.\n",
    "\n",
    "Retorna:\n",
    "o ano do documento com os dados.\n",
    "'''\n",
    "# Dividir o caminho do arquivo em partes\n",
    "\n",
    "def extract_year_from_path(file_path):\n",
    "    year = file_path.split('/')[-1].split('.')[0][-4:]\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45f7bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y1 = file_path.split('/')[-1]\n",
    "# y2 = file_path.split('/')[-1].split('.')[0]\n",
    "# y3 = file_path.split('/')[-1][-4:]\n",
    "\n",
    "# print(year)\n",
    "# print(y1)\n",
    "# print(y2)\n",
    "# print(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "725ca1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Valida se os dados que queremos armazenar já existem no banco de dados. Para fazer isso:\n",
    "1. Use o objeto \"engine\" para se conectar ao banco de dados.\n",
    "2. Crie uma consulta SQL para verificar se há algum registro em \"table_name\" correspondente ao \"year\" (ano) fornecido.\n",
    "3. Execute a consulta SQL.\n",
    "        \n",
    "Retorna:\n",
    "True se os dados já estão armazenados no seu banco de dados. Caso contrário, retorna False. Analisar\n",
    "outros resultados possíveis ao consultar a tabela.\n",
    "'''\n",
    "\n",
    "def data_already_exist(engine, table_name, year):\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            query = text(f'SELECT * FROM {table_name} WHERE ANO_EGRESO={year}')\n",
    "            result = connection.execute(query)\n",
    "            exists = result.fetchone() is not None\n",
    "    except OperationalError as e:\n",
    "        exists = False\n",
    "        \n",
    "    return exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd78c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados em um DataFrame para operações futuras\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path, encoding='latin1', sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f8230be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Args:\n",
    "df (pd.DataFrame): o DataFrame de entrada.\n",
    "threshold (float): a proporção de colunas que podem conter '*' antes que \n",
    "a linha seja removida.\n",
    "        \n",
    "Pré-processar o DataFrame removendo as linhas em que a maioria das colunas contêm o \n",
    "caractere '*'. Você também precisa padronizar os tipos de dados de colunas de acordo com a\n",
    "estrutura de dados apropriada. Inspecionar arquivos CSV diferentes para analisar possíveis problemas. Para fazer isso:\n",
    "            \n",
    "1. Calcule o número de colunas.\n",
    "2. Determine quantos caracteres '*' são permitidos por linha com base no limiar.\n",
    "3. Filtre as linhas que ultrapassaram o número permitido de '*'.\n",
    "4. Converta colunas específicas para o tipo inteiro.\n",
    "5. Renomeie as colunas usando uma lista predefinida de nomes novos.\n",
    "6. Retorne o DataFrame limpo e formatado.\n",
    "                \n",
    "Retorna:\n",
    "pd.DataFrame: o DataFrame limpo.\n",
    "'''\n",
    "\n",
    "def preprocess_data(df, threshold=0.5): # versão antiga: def preprocess_data(df, engine, threshold=0.5):\n",
    "    # Calcular o número de colunas\n",
    "    num_columns = len(df.columns) # ou df.shape[1]\n",
    "\n",
    "     # Determinar o número de caracteres '*' permitidos com base no limiar\n",
    "    allowed_stars = int(num_columns * threshold)\n",
    "\n",
    "    # Filtrar as linhas em que o número de caracteres '*' excede o limiar permitido\n",
    "    cleaned_df = df[df.apply(lambda x: (x == '*').sum() <= allowed_stars, axis=1)]\n",
    "\n",
    "    # Formato de dados\n",
    "    cleaned_df.loc[:,'COMUNA_RESIDENCIA'] = cleaned_df['COMUNA_RESIDENCIA'].astype(int)\n",
    "    cleaned_df.loc[:,'REGION_RESIDENCIA'] = cleaned_df['REGION_RESIDENCIA'].astype(int)\n",
    "    cleaned_df.loc[:,'ANO_EGRESO'] = cleaned_df['ANO_EGRESO'].astype(int)\n",
    "\n",
    "    # Renomear as colunas\n",
    "    new_column_names = ['PERTENENCIA_ESTABLECIMIENTO_SALUD', 'SEXO', 'GRUPO_EDAD', 'ETNIA',\n",
    "       'GLOSA_PAIS_ORIGEN', 'COMUNA_RESIDENCIA', 'GLOSA_COMUNA_RESIDENCIA',\n",
    "       'REGION_RESIDENCIA', 'GLOSA_REGION_RESIDENCIA', 'PREVISION',\n",
    "       'GLOSA_PREVISION', 'ANO_EGRESO', 'DIAG1', 'DIAG2', 'DIAS_ESTADA',\n",
    "       'CONDICION_EGRESO', 'INTERV_Q', 'PROCED']\n",
    "    old_column_names = cleaned_df.columns    \n",
    "    \n",
    "    column_mapping = dict(zip(old_column_names, new_column_names))\n",
    "    cleaned_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "    return cleaned_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ba8fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Criar uma conexão ao banco de dados com \"sqlite:///\"\n",
    "1. Crie uma string de conexão usando um nome de banco de dados conveniente.  Por exemplo,\n",
    "\"sqlite:///{nome do seu banco de dados}.db\". Armazene-a em uma variável.\n",
    "2. Inicie o mecanismo do SQLAlchemy para o banco de dados chamando create_engine(). Passe\n",
    "a variável anterior como um parâmetro dessa função.\n",
    "3. Imprima uma mensagem de confirmação de conexão.\n",
    "4. Retorne o mecanismo do SQLAlchemy para mais interações com o banco de dados.\n",
    "'''\n",
    "\n",
    "def create_db_engine(db_name): # código \"sqlite:///C:\\Users\\carlo\\Downloads\\GIT\\Tripleten\\sprint_12_saude_chile.db\"\n",
    "    connection_string = f'sqlite:///{db_name}'\n",
    "    engine = create_engine(connection_string)\n",
    "    print(f'[INFO]: Conexão verificada: {connection_string}')\n",
    "    return engine\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62b434a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Salvar o DataFrame (df) limpo no seu banco de dados.\n",
    "1. O DataFrame é inserido em uma tabela SQL especificada por table_name.\n",
    "2. Se a tabela já existir, novos dados serão anexados.\n",
    "3. O índice do DataFrame é excluído das colunas da tabela.\n",
    "4. A conexão ao banco de dados é gerenciada usando o mecanismo fornecido.\n",
    "'''\n",
    "\n",
    "def save_to_database(df, engine, table_name):\n",
    "    df.to_sql(name=table_name, con=engine, if_exists='append', index=False)\n",
    "    #return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "37f5fa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Conexão verificada: sqlite:///database/ministerio_de_salud_chile.db\n",
      "[INFO]: Conexão com o banco de dados\n",
      "Caminho do arquivo: c:\\Users\\carlo\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3ee2594d20f59401162676b323c90e71c2979f7df.json\n",
      "[INFO]: Carregar os dados como um DataFrame do Pandas\n",
      "['{\"key\":\"dd7f159f-fbdd-4139-9fd3-3b2d6eceab55\",\"signature_scheme\":\"hmac-sha256\",\"transport\":\"tcp\",\"ip\":\"127.0.0.1\",\"hb_port\":9000,\"control_port\":9001,\"shell_port\":9002,\"stdin_port\":9003,\"iopub_port\":9004,\"kernel_name\":\"python3124jvsc74a57bd08e76f8642360a3358ab06c318ab18c1161224eb3836609d5c16edea6f6e43dba\"}']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'COMUNA_RESIDENCIA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'COMUNA_RESIDENCIA'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOs dados já existem no banco de dados. Nenhuma ação deve ser tomada.\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 34\u001b[0m     raw_data \u001b[38;5;241m=\u001b[39m preprocess_data(raw_data)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[INFO]: Pré-processar os dados\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Salvar os dados em uma nova tabela dentro do banco de dados existente    \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[57], line 33\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(df, threshold)\u001b[0m\n\u001b[0;32m     30\u001b[0m cleaned_df \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: (x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m allowed_stars, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Formato de dados\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m cleaned_df\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOMUNA_RESIDENCIA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cleaned_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOMUNA_RESIDENCIA\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     34\u001b[0m cleaned_df\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREGION_RESIDENCIA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cleaned_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREGION_RESIDENCIA\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     35\u001b[0m cleaned_df\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mANO_EGRESO\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cleaned_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mANO_EGRESO\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'COMUNA_RESIDENCIA'"
     ]
    }
   ],
   "source": [
    "# código para testar seu pipeline\n",
    "\n",
    "def validate_data(engine, table_name):\n",
    "    with engine.connect() as connection:\n",
    "        query = text(f'SELECT ANO_EGRESO, count(*) FROM {table_name} GROUP BY ANO_EGRESO')\n",
    "        result = connection.execute(query)\n",
    "\n",
    "        rows = result.fetchall()\n",
    "        for row in rows[:100]:\n",
    "            print(row)\n",
    "\n",
    "# Analisar o caminho do arquivo usando os argumentos da linha de comando\n",
    "if __name__==\"__main__\":\n",
    "    file_path = parse_arguments()\n",
    "    table_name = 'egresos_pacientes'\n",
    "\n",
    "    # Carregar o banco de dados no seu sistema\n",
    "    engine = create_db_engine('database/ministerio_de_salud_chile.db')\n",
    "    print('[INFO]: Conexão com o banco de dados')\n",
    "\n",
    "    if file_path:\n",
    "        print(f\"Caminho do arquivo: {file_path}\")\n",
    "        year = extract_year_from_path(file_path)\n",
    "\n",
    "        # Carregar seu arquivo CSV em um DataFrame do Pandas\n",
    "        raw_data = load_data(file_path)\n",
    "        print('[INFO]: Carregar os dados como um DataFrame do Pandas')\n",
    "        print(raw_data.columns.tolist())\n",
    "        \n",
    "        # Verificar se os dados já estão no banco de dados\n",
    "        if data_already_exist(engine, table_name, year):\n",
    "            print(f\"Os dados já existem no banco de dados. Nenhuma ação deve ser tomada.\")   \n",
    "        else:\n",
    "            raw_data = preprocess_data(raw_data)\n",
    "            print('[INFO]: Pré-processar os dados')\n",
    "            \n",
    "            # Salvar os dados em uma nova tabela dentro do banco de dados existente    \n",
    "            save_to_database(raw_data, engine, table_name)\n",
    "            print('[INFO]: Carregar os dados no banco de dados')\n",
    "    else:\n",
    "        print('Nenhum caminho foi fornecido')\n",
    "    \n",
    "    validate_data(engine, table_name)\n",
    "    # return\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50acb0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Você pode usar a seguinte linha de comando para executar seu código e armazenar um arquivo. Por exemplo:\n",
    "\n",
    "python test.py -f dbs/EGRESOS_2020/EGRE_DATOS_ABIERTOS_2020.csv\n",
    "'''\n",
    "\n",
    "# \"C:\\Users\\carlo\\Downloads\\GIT\\Tripleten\\sprint_12_saude_chile\\EGRE_DATOS_ABIERTOS_2018.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_arguments()\n",
    "# extract_year_from_path(file_path)\n",
    "# data_already_exists(engine, table_name, year)\n",
    "# load_data(file_path)\n",
    "# preprocess_data(df, threshold=0.5)\n",
    "# create_db_engine(db_name)\n",
    "# save_to_database(df, engine, table_name)\n",
    "# validate_data(engine, table_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
